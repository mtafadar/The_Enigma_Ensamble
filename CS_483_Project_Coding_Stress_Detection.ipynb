{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlaW5KPFIdsC"
   },
   "source": [
    "## <em>A Big Data Mining Approach Project</em>\n",
    "## <b>Stress Detecting from Social Media Interaction</b>\n",
    "## Group name: The Enigma Ensemble\n",
    "\n",
    "### <em>(*) First author:</em>\n",
    "##### Tri Quan Do (tdo22@uic.edu) - Group Leader\n",
    "##### Mosrour Tafadar (mtafad2@uic.edu)\n",
    "##### Hina Khali (hkhali21@uic.edu)\n",
    "##### Safiya Mustafa (smust3@uic.edu)\n",
    "\n",
    "\n",
    "## Project Abstract:\n",
    "Emotional and mental stress are serious issues that can have a significant impact on our well-being. Despite the fact that an emotional experience usually starts as a personal, internal process, it frequently results in the communal sharing of emotions with others. Emotions that are verbally expressed to others by the individual who has experienced them are referred to as being socially shared. People share their emotions with others in more than 80% of all emotional events, regardless of their age, gender, personality type, or culture (Bazarova, Choi, Sosik, Cosley, Whitlock 1). Due to social media's widespread use, people are accustomed to posting about their everyday activities and connecting with acquaintances on these platforms, making it possible to use information from online social networks to identify stress.\n",
    "\n",
    "## Project Introduction\n",
    "\n",
    "The initial step of this research project involves identifying a set of words that are commonly associated with emotional stress. Using this set of words, the models aim to compute an overall stress score for each individual under investigation. However, it is critical to acknowledge that some words may carry a higher intensity than others. Hence, the project purpose will segregate the identified set of words into distinct categories based on their intensity levels, namely high, moderate, and low to parallel conduct a word frequency analysis to identify words or phrases that occur frequently, specifically those that pertain to emotions or stress. This research approach is expected to provide valuable insights into the underlying patterns and associations between language use and emotional stress, thereby contributing to the existing knowledge base on the topic.<br><br>\n",
    "\n",
    "Robust technologies for processing and analyzing massive amounts of social media data include Support Vector Machines (SVM) and MapReduce, which can be used to forecast stress levels based on social media posts. SVM is a machine learning algorithm that divides the data into classes before identifying the hyperplane that best distinguishes the classes. Large datasets can be processed concurrently on a distributed computing system using the model and software framework known as MapReduce\n",
    "\n",
    "Full project information could be found here <\"add link to document\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "###########   ENVIRONMENT SETTING UP   ################\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install -U scikit-learn\n",
    "!pip install seaborn\n",
    "!pip install pyspark\n",
    "!pip install -U -q PyDrive\n",
    "!apt install openjdk-8-jdk-headless -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXsy0Z5MJ39m"
   },
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "## These code below could generate error when working on non-google colab environment    ##\n",
    "## Please comment those code below if you work on local machine                          ##\n",
    "###########################################################################################\n",
    "\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "#\n",
    "# # Authenticate and create the PyDrive client\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DjsoAutlJ8Nh"
   },
   "outputs": [],
   "source": [
    "from oauth2client.crypt import PyCryptoSigner\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Modeling for Machine Learning Task\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGW5OPAZccM4"
   },
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>profile_yn</th>\n",
       "      <th>profile_yn:confidence</th>\n",
       "      <th>created</th>\n",
       "      <th>...</th>\n",
       "      <th>profileimage</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sidebar_color</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>815719226</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:24</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12/5/13 1:48</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/414342229...</td>\n",
       "      <td>0</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110964</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>main; @Kan1shk3</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>815719227</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:30</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/1/12 13:51</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/539604221...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>ÛÏIt felt like they were my friends and I was...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7471</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>815719228</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:33</td>\n",
       "      <td>male</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/28/14 11:30</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/657330418...</td>\n",
       "      <td>1</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5617</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>clcncl</td>\n",
       "      <td>Belgrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>815719229</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:10</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6/11/09 22:39</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/259703936...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1693</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>815719230</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/27/15 1:15</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/16/14 13:23</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/564094871...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31462</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20045</th>\n",
       "      <td>815757572</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8/5/15 21:16</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/656793310...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>@lookupondeath ...Fine, and I'll drink tea too...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>783</td>\n",
       "      <td>10/26/15 13:20</td>\n",
       "      <td>6.587400e+17</td>\n",
       "      <td>Verona ªÁ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20046</th>\n",
       "      <td>815757681</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8/15/12 21:17</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/639815429...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Greg Hardy you a good player and all but don't...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13523</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>Kansas City, MO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20047</th>\n",
       "      <td>815757830</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9/3/12 1:17</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/655473271...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>You can miss people and still never want to se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26419</td>\n",
       "      <td>10/26/15 13:20</td>\n",
       "      <td>6.587400e+17</td>\n",
       "      <td>Lagos Nigeria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20048</th>\n",
       "      <td>815757921</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0.8489</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/6/12 23:46</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/657716093...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@bitemyapp i had noticed your tendency to pee ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56073</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>Texas Hill Country</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20049</th>\n",
       "      <td>815757985</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/14/14 17:22</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/655134724...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>I think for my APUSH creative project I'm goin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2922</td>\n",
       "      <td>10/26/15 13:19</td>\n",
       "      <td>6.587400e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20050 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0      815719226    False   finalized                   3    10/26/15 23:24   \n",
       "1      815719227    False   finalized                   3    10/26/15 23:30   \n",
       "2      815719228    False   finalized                   3    10/26/15 23:33   \n",
       "3      815719229    False   finalized                   3    10/26/15 23:10   \n",
       "4      815719230    False   finalized                   3     10/27/15 1:15   \n",
       "...          ...      ...         ...                 ...               ...   \n",
       "20045  815757572     True      golden                 259               NaN   \n",
       "20046  815757681     True      golden                 248               NaN   \n",
       "20047  815757830     True      golden                 264               NaN   \n",
       "20048  815757921     True      golden                 250               NaN   \n",
       "20049  815757985     True      golden                 249               NaN   \n",
       "\n",
       "       gender  gender:confidence profile_yn  profile_yn:confidence  \\\n",
       "0        male             1.0000        yes                    1.0   \n",
       "1        male             1.0000        yes                    1.0   \n",
       "2        male             0.6625        yes                    1.0   \n",
       "3        male             1.0000        yes                    1.0   \n",
       "4      female             1.0000        yes                    1.0   \n",
       "...       ...                ...        ...                    ...   \n",
       "20045  female             1.0000        yes                    1.0   \n",
       "20046    male             1.0000        yes                    1.0   \n",
       "20047    male             1.0000        yes                    1.0   \n",
       "20048  female             0.8489        yes                    1.0   \n",
       "20049  female             1.0000        yes                    1.0   \n",
       "\n",
       "              created  ...                                       profileimage  \\\n",
       "0        12/5/13 1:48  ...  https://pbs.twimg.com/profile_images/414342229...   \n",
       "1       10/1/12 13:51  ...  https://pbs.twimg.com/profile_images/539604221...   \n",
       "2      11/28/14 11:30  ...  https://pbs.twimg.com/profile_images/657330418...   \n",
       "3       6/11/09 22:39  ...  https://pbs.twimg.com/profile_images/259703936...   \n",
       "4       4/16/14 13:23  ...  https://pbs.twimg.com/profile_images/564094871...   \n",
       "...               ...  ...                                                ...   \n",
       "20045    8/5/15 21:16  ...  https://pbs.twimg.com/profile_images/656793310...   \n",
       "20046   8/15/12 21:17  ...  https://pbs.twimg.com/profile_images/639815429...   \n",
       "20047     9/3/12 1:17  ...  https://pbs.twimg.com/profile_images/655473271...   \n",
       "20048   11/6/12 23:46  ...  https://pbs.twimg.com/profile_images/657716093...   \n",
       "20049   4/14/14 17:22  ...  https://pbs.twimg.com/profile_images/655134724...   \n",
       "\n",
       "       retweet_count sidebar_color  \\\n",
       "0                  0        FFFFFF   \n",
       "1                  0        C0DEED   \n",
       "2                  1        C0DEED   \n",
       "3                  0        C0DEED   \n",
       "4                  0             0   \n",
       "...              ...           ...   \n",
       "20045              0        C0DEED   \n",
       "20046              0             0   \n",
       "20047              0        C0DEED   \n",
       "20048              0             0   \n",
       "20049              0        C0DEED   \n",
       "\n",
       "                                                    text tweet_coord  \\\n",
       "0      Robbie E Responds To Critics After Win Against...         NaN   \n",
       "1      ÛÏIt felt like they were my friends and I was...         NaN   \n",
       "2      i absolutely adore when louis starts the songs...         NaN   \n",
       "3      Hi @JordanSpieth - Looking at the url - do you...         NaN   \n",
       "4      Watching Neighbours on Sky+ catching up with t...         NaN   \n",
       "...                                                  ...         ...   \n",
       "20045  @lookupondeath ...Fine, and I'll drink tea too...         NaN   \n",
       "20046  Greg Hardy you a good player and all but don't...         NaN   \n",
       "20047  You can miss people and still never want to se...         NaN   \n",
       "20048  @bitemyapp i had noticed your tendency to pee ...         NaN   \n",
       "20049  I think for my APUSH creative project I'm goin...         NaN   \n",
       "\n",
       "      tweet_count   tweet_created      tweet_id      tweet_location  \\\n",
       "0          110964  10/26/15 12:40  6.587300e+17     main; @Kan1shk3   \n",
       "1            7471  10/26/15 12:40  6.587300e+17                 NaN   \n",
       "2            5617  10/26/15 12:40  6.587300e+17              clcncl   \n",
       "3            1693  10/26/15 12:40  6.587300e+17       Palo Alto, CA   \n",
       "4           31462  10/26/15 12:40  6.587300e+17                 NaN   \n",
       "...           ...             ...           ...                 ...   \n",
       "20045         783  10/26/15 13:20  6.587400e+17          Verona ªÁ   \n",
       "20046       13523  10/26/15 12:40  6.587300e+17     Kansas City, MO   \n",
       "20047       26419  10/26/15 13:20  6.587400e+17      Lagos Nigeria    \n",
       "20048       56073  10/26/15 12:40  6.587300e+17  Texas Hill Country   \n",
       "20049        2922  10/26/15 13:19  6.587400e+17                 NaN   \n",
       "\n",
       "                    user_timezone  \n",
       "0                         Chennai  \n",
       "1      Eastern Time (US & Canada)  \n",
       "2                        Belgrade  \n",
       "3      Pacific Time (US & Canada)  \n",
       "4                             NaN  \n",
       "...                           ...  \n",
       "20045                         NaN  \n",
       "20046                         NaN  \n",
       "20047                         NaN  \n",
       "20048                         NaN  \n",
       "20049                         NaN  \n",
       "\n",
       "[20050 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First reading the data\n",
    "data = pd.read_csv('Training Data/twitter_content.csv', encoding='ISO-8859-1')\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20050 entries, 0 to 20049\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   _unit_id               20050 non-null  int64  \n",
      " 1   _golden                20050 non-null  bool   \n",
      " 2   _unit_state            20050 non-null  object \n",
      " 3   _trusted_judgments     20050 non-null  int64  \n",
      " 4   _last_judgment_at      20000 non-null  object \n",
      " 5   gender                 19953 non-null  object \n",
      " 6   gender:confidence      20024 non-null  float64\n",
      " 7   profile_yn             20050 non-null  object \n",
      " 8   profile_yn:confidence  20050 non-null  float64\n",
      " 9   created                20050 non-null  object \n",
      " 10  description            16306 non-null  object \n",
      " 11  fav_number             20050 non-null  int64  \n",
      " 12  gender_gold            50 non-null     object \n",
      " 13  link_color             20050 non-null  object \n",
      " 14  name                   20050 non-null  object \n",
      " 15  profile_yn_gold        50 non-null     object \n",
      " 16  profileimage           20050 non-null  object \n",
      " 17  retweet_count          20050 non-null  int64  \n",
      " 18  sidebar_color          20050 non-null  object \n",
      " 19  text                   20050 non-null  object \n",
      " 20  tweet_coord            159 non-null    object \n",
      " 21  tweet_count            20050 non-null  int64  \n",
      " 22  tweet_created          20050 non-null  object \n",
      " 23  tweet_id               20050 non-null  float64\n",
      " 24  tweet_location         12566 non-null  object \n",
      " 25  user_timezone          12252 non-null  object \n",
      "dtypes: bool(1), float64(3), int64(5), object(17)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#Let's check overall info of the data\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data we can see that  there are total of 200050 rows and 26 columns. Below is the description of  each of the  column\n",
    "\n",
    "The data contains the following fields:\n",
    "\n",
    "**unitid:** a unique id for the user  \n",
    "**_golden:**  whether the user was included in the gold standard for the model; TRUE or FALSE  \n",
    "\n",
    "\n",
    "**unitstate:** state of the observation; one of finalized (for contributor-judged) or golden (for gold standard observations)\n",
    "trustedjudgments: number of trusted judgments (int); always 3 for non-golden, and what may be a unique id for gold standard observations  \n",
    "\n",
    "**lastjudgment_at:** date and time of last contributor judgment; blank for gold standard observations  \n",
    "\n",
    "**gender:** one of male, female, or brand (for non-human profiles)  \n",
    "\n",
    "**gender:confidence:**  a float representing confidence in the provided gender  \n",
    "\n",
    "**profile_yn:** “no” here seems to mean that the profile was meant to be part of the dataset but was not available when contributors went to judge it\n",
    "\n",
    "\n",
    "**profile_yn:** confidence: confidence in the existence/non-existence of the profile  \n",
    "\n",
    "**created:** date and time when the profile was created  \n",
    "\n",
    "**description:** the user’s profile description  \n",
    "\n",
    "**fav_number:** number of tweets the user has favourited\n",
    "\n",
    "\n",
    "**gender_gold:** if the profile is golden, what is the gender?  \n",
    "\n",
    "**link_color:** the link colour on the profile, as a hex value\n",
    "\n",
    "\n",
    "**name:** the user’s name  \n",
    "\n",
    "**profileyngold:** whether the profile y/n value is golden  \n",
    "\n",
    "\n",
    "**profileimage:** a link to the profile image  \n",
    "\n",
    "**retweet_count:** number of times the user has retweeted (or possibly, been retweeted)  \n",
    "\n",
    "**sidebar_color:** color of the profile sidebar, as a hex value  \n",
    "\n",
    "**text:** text of a random one of the user’s tweets  \n",
    "\n",
    "**tweet_coord:** if the user has location turned on, the coordinates as a string with the format “[latitude, longitude]”  \n",
    "\n",
    "**tweet_count:** number of tweets that the user has posted  \n",
    "\n",
    "**tweet_created:**  when the random tweet (in the text column) was created  \n",
    "\n",
    "**tweet_id:** the tweet id of the random tweet \n",
    "\n",
    "**tweet_location:** location of the tweet; seems to not be particularly normalized  \n",
    "\n",
    "**user_timezone:** the timezone of the user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yjb3mj5dchZW"
   },
   "source": [
    "## Data Cleaning Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def read_many(file_path=\"\", expect_col=[], file_list=[], encode=\"\", read_many=False):\n",
    "  \"\"\"\n",
    "  Reads and returns multiple CSV files as pandas dataframes.\n",
    "\n",
    "  Args:\n",
    "      file_path (str): Optional file path to read CSV files from.\n",
    "      expect_col (list): Optional list of expected column names to extract from each CSV file.\n",
    "      file_list (list): List of CSV file names to read.\n",
    "      encode (str): Optional encoding type for reading CSV files.\n",
    "      read_many (bool): Optional boolean to indicate whether to read multiple CSV files.\n",
    "\n",
    "  Returns:\n",
    "      list: A list of pandas dataframes, where each dataframe corresponds to a CSV file in file_list.\n",
    "  \"\"\"\n",
    "\n",
    "  dataFrame_list = []\n",
    "\n",
    "  for f_name in file_list:\n",
    "    data_csv = pd.read_csv(f_name)\n",
    "    dataFrame_list.append(data_csv)\n",
    "\n",
    "  dataFrames_Final = []\n",
    "  # Drop unnecessary columns that only retrieve from expected one\n",
    "  if len(expect_col) > 0:\n",
    "    for frame in dataFrame_list:\n",
    "      new_frame = frame.loc[:, expect_col]\n",
    "      dataFrames_Final.append(new_frame)\n",
    "  else:\n",
    "    dataFrames_Final = dataFrame_list\n",
    "\n",
    "  return dataFrames_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def read_one(file_path=\"\", expect_col=[], encode=\"\", drop_NaN=False):\n",
    "  \"\"\"\n",
    "  Reads a single CSV file as a pandas dataframe, drops NaN rows and columns, and returns the resulting dataframe.\n",
    "\n",
    "  Args:\n",
    "      file_path (str): Optional file path to read the CSV file from.\n",
    "      expect_col (list): Optional list of expected column names to extract from the CSV file.\n",
    "      encode (str): Optional encoding type for reading the CSV file.\n",
    "      drop_NaN (bool): Optional boolean to indicate whether to drop NaN rows and columns.\n",
    "\n",
    "  Returns:\n",
    "      pandas.DataFrame: A pandas dataframe that corresponds to the CSV file in file_path, after cleaning.\n",
    "\n",
    "  Notes:\n",
    "      If drop_NaN is True, rows and columns with NaN values will be dropped. If expect_col is non-empty,\n",
    "      only the specified columns will be retained. If both options are used, NaN rows and columns will be\n",
    "      dropped first, and then the specified columns will be retained.\n",
    "  \"\"\"\n",
    "\n",
    "  # Case when import 1 single file only\n",
    "  data_csv = pd.read_csv(file_path, encoding=encode)\n",
    "\n",
    "  # Drop un-clean data or data row incomplete\n",
    "  if drop_NaN:\n",
    "    data_csv.dropna(inplace=True)           # drop rows missed value\n",
    "    data_csv.to_csv(\"twitter_content_wb.csv\", index=False) # Write back\n",
    "\n",
    "  # Drop unnecessary columns that only retrieve from expected one\n",
    "  if len(expect_col) > 0:\n",
    "    data_csv = data_csv.loc[:, expect_col]\n",
    "\n",
    "  return data_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Clean the data to extract expected columns\n",
    "def data_import(file_path=\"\", expect_col=[], file_list=[], encode=\"\", read_many=False):\n",
    "  \"\"\"\n",
    "    This function imports crime data from a CSV file or\n",
    "    a list of CSV files. It drops missing values and\n",
    "    unnecessary columns from the data and returns\n",
    "    a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): the path to the CSV file to import\n",
    "      (default: \"\")\n",
    "    expect_col (list): a list of column names to keep in the data\n",
    "      (default: [])\n",
    "    file_list (list): a list of file paths to import if read_many is True\n",
    "      (default: [])\n",
    "    read_many (bool): True if importing multiple files, False if importing a single file\n",
    "      (default: False)\n",
    "\n",
    "    Returns:\n",
    "    A Pandas DataFrame containing the cleaned crime data.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    # When reading multiples file, return a list of frames\n",
    "    if read_many is True:\n",
    "      return read_many(file_path, expect_col, file_list, encode, read_many)\n",
    "\n",
    "    # Case when import 1 single file only\n",
    "    return read_one(file_path, expect_col, encode)\n",
    "\n",
    "  # Internal error occurred\n",
    "  except Exception as e:\n",
    "    try:\n",
    "      # Case when import 1 single file only\n",
    "      return read_one(file_path, expect_col, encode)\n",
    "    except Exception as e:\n",
    "      print(\"Internal errors occurs for loading csv file. Try again\", str(e))\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Data file storage - user can change CONST_PATH to his/her location\n",
    "CONST_PATHDIR = \"Training Data/twitter_content.csv\"\n",
    "CONST_ENCODES = 'ISO-8859-1'\n",
    "signi_columns = ['_unit_id', 'gender', 'created', 'description', 'name', 'retweet_count','text']\n",
    "twitter_Frame = data_import(file_path=CONST_PATHDIR, expect_col=signi_columns, encode=CONST_ENCODES)\n",
    "twitter_Frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "twitter_Frame.head(10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
