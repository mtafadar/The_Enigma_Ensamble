{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlaW5KPFIdsC"
      },
      "source": [
        "## <em>A Big Data Mining Approach Project</em>\n",
        "## <b>Stress Detecting from Social Media Interaction</b>\n",
        "## Group name: The Enigma Ensemble\n",
        "\n",
        "### <em>(*) First author:</em>\n",
        "##### Tri Quan Do (tdo22@uic.edu) - Group Leader\n",
        "##### Mosrour Tafadar (mtafad2@uic.edu)\n",
        "##### Hina Khali (hkhali21@uic.edu)\n",
        "##### Safiya Mustafa (smust3@uic.edu)\n",
        "\n",
        "\n",
        "## Project Abstract:\n",
        "Emotional and mental stress are serious issues that \n",
        "can have a significant impact on our well-being. \n",
        "Despite the fact that an emotional experience usually \n",
        "starts as a personal, internal process, it frequently \n",
        "results in the communal sharing of emotions with \n",
        "others. Emotions that are verbally expressed to others \n",
        "by the individual who has experienced them are \n",
        "referred to as being socially shared. People share their \n",
        "emotions with others in more than 80% of all emotional \n",
        "events, regardless of their age, gender, personality \n",
        "type, or culture (Bazarova, Choi, Sosik, Cosley, \n",
        "Whitlock 1). Due to social media's widespread use, \n",
        "people are accustomed to posting about their everyday \n",
        "activities and connecting with acquaintances on these \n",
        "platforms, making it possible to use information from \n",
        "online social networks to identify stress.\n",
        "\n",
        "## Project Introduction\n",
        "\n",
        "The initial step of this research project involves \n",
        "identifying a set of words that are commonly associated \n",
        "with emotional stress. Using this set of words, the \n",
        "models aim to compute an overall stress score for each \n",
        "individual under investigation. However, it is critical to \n",
        "acknowledge that some words may carry a higher \n",
        "intensity than others. Hence, the project purpose will \n",
        "segregate the identified set of words into distinct \n",
        "categories based on their intensity levels, namely high, \n",
        "moderate, and low to parallelly conduct a word \n",
        "frequency analysis to identify words or phrases that \n",
        "occur frequently, specifically those that pertain to \n",
        "emotions or stress. This research approach is expected to \n",
        "provide valuable insights into the underlying patterns \n",
        "and associations between language use and emotional \n",
        "stress, thereby contributing to the existing knowledge \n",
        "base on the topic.<br><br>\n",
        "\n",
        "Robust technologies for processing and analyzing \n",
        "massive amounts of social media data include Support \n",
        "Vector Machines (SVM) and MapReduce, which can be \n",
        "used to forecast stress levels based on social media posts. \n",
        "SVM is a machine learning algorithm that divides the \n",
        "data into classes before identifying the hyperplane that \n",
        "best distinguishes the classes. Large datasets can be \n",
        "processed concurrently on a distributed computing \n",
        "system using the model and software framework known \n",
        "as MapReduce\n",
        "\n",
        "Full project information could be found here <\"add link to document\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PXTnTiXzIl7b"
      },
      "outputs": [],
      "source": [
        "#######################################################\n",
        "###########   ENVIRONMENT SETTING UP   ################\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install -U scikit-learn\n",
        "!pip install seaborn\n",
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXsy0Z5MJ39m"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjsoAutlJ8Nh"
      },
      "outputs": [],
      "source": [
        "from oauth2client.crypt import PyCryptoSigner\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Modeling for Machine Learning Task\n",
        "from sklearn.linear_model import LinearRegression \n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGW5OPAZccM4"
      },
      "source": [
        "## Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjb3mj5dchZW"
      },
      "source": [
        "## Data Cleaning Description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "640PhTWAcgba"
      },
      "outputs": [],
      "source": [
        "# Clean the data to extract expected columns\n",
        "def data_import(file_path=\"\", sig_col=[]):\n",
        "  try:\n",
        "    dataFrame = pd.read_csv(file_path)\n",
        "    \n",
        "  except Exception as e:\n",
        "    print(\"Interal errors when loading dataFrame, try again\", str(e))\n",
        "    return None\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}